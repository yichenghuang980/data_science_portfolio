<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Compare Fake News Detection Performance with Glove and Word2Vec Embedding in Keras | Yicheng Huang</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Fake News Detection">
    <meta name="generator" content="Hugo 0.81.0" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    

  
  
    <link rel="stylesheet" href="https://yichenghuang980.github.io/data_science_portfolio/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css" >
  




    
      

    

    
    
    <meta property="og:title" content="Compare Fake News Detection Performance with Glove and Word2Vec Embedding in Keras" />
<meta property="og:description" content="Fake News Detection" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yichenghuang980.github.io/data_science_portfolio/projects/fakenews/" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2020-11-24T11:14:48-04:00" />
<meta property="article:modified_time" content="2020-11-24T11:14:48-04:00" /><meta property="og:site_name" content="Yicheng Huang" />

<meta itemprop="name" content="Compare Fake News Detection Performance with Glove and Word2Vec Embedding in Keras">
<meta itemprop="description" content="Fake News Detection"><meta itemprop="datePublished" content="2020-11-24T11:14:48-04:00" />
<meta itemprop="dateModified" content="2020-11-24T11:14:48-04:00" />
<meta itemprop="wordCount" content="768">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Compare Fake News Detection Performance with Glove and Word2Vec Embedding in Keras"/>
<meta name="twitter:description" content="Fake News Detection"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://yichenghuang980.github.io/data_science_portfolio/images/fakeNews/fake_news.jpg');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://yichenghuang980.github.io/data_science_portfolio/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Yicheng Huang
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://yichenghuang980.github.io/data_science_portfolio/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://yichenghuang980.github.io/data_science_portfolio/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://yichenghuang980.github.io/data_science_portfolio/projects/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      







<a href="https://www.linkedin.com/in/yicheng-huang-74320313b/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/yichenghuang980" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>








    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Compare Fake News Detection Performance with Glove and Word2Vec Embedding in Keras</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              Fake News Detection
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      





      <h1 class="f1 athelas mt3 mb1">Compare Fake News Detection Performance with Glove and Word2Vec Embedding in Keras</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2020-11-24T11:14:48-04:00">November 24, 2020</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><h1 id="background">Background</h1>
<p>In human society, words carry meaning through symbols. However, despite that symbols are easy for humans to understand, such comprehension has been proven difficult for computational systems. To address this problem, researchers introduced word embedding methods. Word embedding, also known as distributed word representation, represents any given word in vector form. The resulting vector of numbers, known as a word vector, is associated with the meaning of that given word in a mathematical form.</p>
<p>Word embedding can capture both the semantic and syntactic information of words. With word vectors, researchers can analyze the similarities between words directly (word similarity and word analogies). Furthermore, word vectors can be used as input features in various models for high-level tasks including sentiment analysis, topic modeling, and topic classification.</p>
<p>Before word2Vec, words were encoded through statistics. One commonly used technique was SVD (Singular Value Decomposition), which is a dimensionality reduction method on a document by term matrix. SVD is then used to process LSI (Latent Semantic Indexing) which can produce term to term similarities, document to document similarities, and term to document similarities. However, since SVD is based on matrix decomposition, the dimensions of the matrix change when the dictionary changes, and the whole decomposition must be re-calculated when we add a word. It is also very sensitive to word frequency imbalance, so we often must pre-process the documents to remove stopwords and normalize the corpus(through lemmatization orstemming). As a result, SVD is computationally expensive and not suitable for large dictionaries or corpora.</p>
<p>In this project, we evaluate two word embedding methods – word2vec and GloVe – and compare their performance in an LSTM driven fake news detection model.</p>
<h1 id="word2vec">Word2Vec</h1>
<p>To address the need for a simpler methodology, Mikolov et al. introduced word2vec, which is an unsupervised learning method to develop embeddings that capture relationships between words and documents. Word2vec follows one of two main methods, either predicting a target word based on surrounding words, known as continuous bag-of-words (CBOW), or predicting surrounding context words based on a given target word, known as skip-gram (SG). To start, word2vec initializes all focus word vectors and context word vectors with random weights. Then word2vec extracts a word window (focus word in the middle, certain number of context words before and after the focus word) and calculates the vector values to predict the pattern of words in the word window. As a result, words that share context, and contexts that share many words lay near each other in the vector space.</p>
<h1 id="glove">GloVe</h1>
<p>Based on word2vec, Pennington et al. developed an unsupervised learning algorithm called Global vector for word representation (GloVe) in 2014. The team’s aim was to improve word prediction performance with word statistics over the entire corpus. The main concept in GloVe involves building a counting-based co-occurrence matrix for all unique words, and then calculating the probability ratios for two given words. The co-occurrence matrix is used to compute whether two words are highly correlated. This conditional probability is calculated by number of times word ice and word solid show up together divided by number of times word ice appears in the entire corpus. If the word solid often shows up with the word ice, the conditional probability will approach to 1, and vice versa.</p>
<p>The global co-occurrence aspect of GloVe has been shown to carry two unique advantages, better performance on analogy tasks than word2vec, and having more context information for each trained word. However, GloVe is limited in that storing the co-occurrence matrix requires significantly more memory than word2vec.</p>
<h1 id="datasets">Datasets</h1>
<p><a href="https://nlp.stanford.edu/projects/glove/">Stanford GloVe project: wikipedia/twitter/google pretrained word vectorizers</a></p>
<h1 id="most-frequent-words">Most Frequent Words</h1>
<p><img src="https://yichenghuang980.github.io/data_science_portfolio/images/fakeNews/wordCloud.png" alt=""></p>
<h1 id="similarity-task">Similarity Task</h1>
<p><img src="https://yichenghuang980.github.io/data_science_portfolio/images/fakeNews/similarityTask.png" alt=""></p>
<p>Take the picture above as an example, It is observable that results from GloVe is closer to what humans would say if given a word to find its similar words. In other words, GloVe might be able to find synonyms while Word2Vec focuses on words that can form grammatically correct phrase or are grammatically close. It could be because GloVe is designed to look at the entire corpus while Word2Vec only looks at a tiny piece of corpus which has proximity to the given words.</p>
<h1 id="prediction-task">Prediction Task</h1>
<p><img src="https://yichenghuang980.github.io/data_science_portfolio/images/fakeNews/fakeNewsAccuracy.png" alt=""></p>
<h1 id="conclusion">Conclusion</h1>
<p>Glove and Word2Vec give quite different results when performing similarity tasks. Results from GloVe are closer to what humans would give.</p>
<p>However, their accuracy in prediction task do not vary much. It could be because our train and test sets (4k+ observations) are not large enough to uncover difference between these two embeddings in prediction tasks.</p>
<h1 id="more-details">More Details</h1>
<p><a href="https://github.com/yichenghuang980/LSTM-Word-Embeddings-For-Fake-News-Detection">The complete report and code can be acccess here.</a></p>
<p>Tip: open the link in a new tab to avoid switching back and forth.</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://yichenghuang980.github.io/data_science_portfolio" >
    &copy;  Yicheng Huang 2021 
  </a>
    <div>







<a href="https://www.linkedin.com/in/yicheng-huang-74320313b/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="https://github.com/yichenghuang980" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>







</div>
  </div>
</footer>

  </body>
</html>
